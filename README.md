# 天池&ICDAR2023 篡改图像检测比赛方案

## 赛道1：分类
队伍名称：严重摆烂

初赛分数：83.23

复赛分数：80.55


### 方案设计
将图片resize成512/768，使用efficient-net-b6作为backbone进行分类，后面加了两个线性层用于分类，训练10个epoch左右，(挑选验证集上最好的模型)
- 512：线上提交：81.92
- 768：线上提交：81.89
- 
两个模型的预测结果进行融合：83.23(初赛)

### 小结
赛道一真的是严重摆烂，互联网寒气逼人，暑期实习真的太难找啦，在最开始的几天提交了几次之后，后面就没有再优化了，能进复赛完全是因为运气好。


## 赛道2：分割
队伍名称：彻底摆烂

初赛分数：2.88

复赛分数：2.62

### 方案设计
篡改和没篡改过的图像分别划分20%作为验证集，如果按照官方的计分方式，每一轮验证的时间比较长，所以我在挑选模型的时候是按照在篡改验证集上iou分数来进行挑选的（阈值设为0.5）。后面发现其实仔细研究一下官方计算分数的方法非常重要！！！！！！

#### backbone的选择
采用convnext作为encoder，尝试过使用efficientnet，swin-v2(base)，和convnext(base)，convnext的分数是最高的。Decoder使用了UNet结构，尝试过UperNet，UNet，UNetPlusPlus，UperNet效果比较差，考虑到篡改检测需要比较浅层的纹理信息，而UNet和UNetPlusPlus的效果差不多，就用了UNet。个人感觉Decoder差不多就行了，encoder强才是真的强。
当把所有的图像都resize成512进行训练和推理时，三个不同的backbone分数是：
- efficientnet：线下iou：0.1290，线上分数：0.9620
- swin-v2：线下iou：0.1374，线上分数：1.2087
- convnext：线下iou：0.1723，线上分数：1.5737

使用convnext-large或者xlarge分数还是会再往上升的，但是显卡不够，训练效率太低了，所以没有采用

#### 损失函数
损失函数没有做特别的调整，就是ce loss + dice loss，权重的影响也不是特别大，凭感觉设的。

#### 上分策略
不能算是一种策略但是非常重要！！！！！！

我在提交的时候出现了很多次线下验证分数非常高，但是提交的结果却接近0的情况，这个应该是很多选手都遇到的。我分析了一下评分的函数，是先从没有篡改过的图像里面计算阈值，再用这个阈值去计算篡改图像的iou，然后我分析了一下提交分数特别低的几次结果，几乎都是在没篡改过的图像上出现了虚警，哪怕出现虚警的区域非常小，导致计算出来的阈值特别高，都接近255了。所以我后面考虑结合分割的结果对分类的结果进行修正，具体来说就是对于分类篡改概率大于0.5的，不做处理，对于分类概率小于0.5的，分割的结果乘上分类概率，做了这一步，线上分数可以直接提高0.3-0.5
1. 放大分辨率，512 -> 768 -> 1024 -> 1280，为了提高迭代效率，我每一次放大分辨率都是用上一步的模型初始化的，线上分数分别从1.7610->1.8928->2.0337->2.3958
2. 滑动窗口，考虑到对图像进行缩放还是损失了很多细节信息，所以用滑动窗口的方法对图像进行裁剪，分别使用768，1024的尺寸对原始图像进行裁剪，训练集为完整图像、裁剪后的图像，都resize成512，最后推理的时候也是采用滑窗和resize的结果相结合的方式，线上分数2.5893.
3. 模型融合：本来我是不想用的，但是太卷了，所以挑了三个比较好的模型融合了一下。

#### 小结
复赛还是彻底摆了。。。。。。
总体来说还是因为去年参加了类似的比赛，所以直接用了去年的一些经验，少走了一些弯路。
